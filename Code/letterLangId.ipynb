{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "fa94fa03635b191b62c3bdd9f3230a84a78e4138ecf162410bfe25b45739a4b0"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read English Training Data\n",
    "# By: Benjamin Kulis\n",
    "import string, math\n",
    "\n",
    "input_file = open('../Data/Input/LangId.train.English', 'r', encoding = 'Latin1')\n",
    "lines = input_file.readlines()\n",
    "input_file.close()\n",
    "\n",
    "words = []\n",
    "english_vocab = []\n",
    "\n",
    "for l in lines:\n",
    "    for p in string.punctuation:\n",
    "        l = l.replace(p, \"\")\n",
    "    words.append(l.strip().lower())\n",
    "    \n",
    "i = 0\n",
    "while i < len(words):\n",
    "    english_vocab.extend(words[i].split())\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create English Bigram\n",
    "english_currLetter = {}\n",
    "english_prevLetter = {}\n",
    "english_bigram = {}\n",
    "\n",
    "for word in english_vocab:\n",
    "    for i in range(len(word) - 1):\n",
    "        if word[i : i + 2] in english_currLetter.keys():\n",
    "            english_currLetter[word[i : i + 2]] += 1\n",
    "        else:\n",
    "            english_currLetter[word[i : i + 2]] = 1\n",
    "    for i in range(len(word)):\n",
    "        if word[i] in english_prevLetter.keys():\n",
    "            english_prevLetter[word[i]] += 1\n",
    "        else:\n",
    "            english_prevLetter[word[i]] = 1\n",
    "\n",
    "for key in english_currLetter.keys():\n",
    "    english_bigram[(key, key[0])] = english_currLetter[key] / english_prevLetter[key[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read French Training Data\n",
    "input_file = open('../Data/Input/LangId.train.French', 'r', encoding = 'Latin1')\n",
    "lines = input_file.readlines()\n",
    "input_file.close()\n",
    "\n",
    "words = []\n",
    "french_vocab = []\n",
    "\n",
    "for l in lines:\n",
    "    for p in string.punctuation:\n",
    "        l = l.replace(p, \"\")\n",
    "    words.append(l.strip().lower())\n",
    "    \n",
    "i = 0\n",
    "while i < len(words):\n",
    "    french_vocab.extend(words[i].split())\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create French Bigram\n",
    "french_currLetter = {}\n",
    "french_prevLetter = {}\n",
    "french_bigram = {}\n",
    "\n",
    "for word in french_vocab:\n",
    "    for i in range(len(word) - 1):\n",
    "        if word[i : i + 2] in french_currLetter.keys():\n",
    "            french_currLetter[word[i : i + 2]] += 1\n",
    "        else:\n",
    "            french_currLetter[word[i : i + 2]] = 1\n",
    "    for i in range(len(word)):\n",
    "        if word[i] in french_prevLetter.keys():\n",
    "            french_prevLetter[word[i]] += 1\n",
    "        else:\n",
    "            french_prevLetter[word[i]] = 1\n",
    "\n",
    "for key in french_currLetter.keys():\n",
    "    french_bigram[(key, key[0])] = french_currLetter[key] / french_prevLetter[key[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Italian Training Data\n",
    "input_file = open('../Data/Input/LangId.train.Italian', 'r', encoding = 'Latin1')\n",
    "lines = input_file.readlines()\n",
    "input_file.close()\n",
    "\n",
    "words = []\n",
    "italian_vocab = []\n",
    "\n",
    "for l in lines:\n",
    "    for p in string.punctuation:\n",
    "        l = l.replace(p, \"\")\n",
    "    words.append(l.strip().lower())\n",
    "    \n",
    "i = 0\n",
    "while i < len(words):\n",
    "    italian_vocab.extend(words[i].split())\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Italian Bigram\n",
    "italian_currLetter = {}\n",
    "italian_prevLetter = {}\n",
    "italian_bigram = {}\n",
    "\n",
    "for word in italian_vocab:\n",
    "    for i in range(len(word) - 1):\n",
    "        if word[i : i + 2] in italian_currLetter.keys():\n",
    "            italian_currLetter[word[i : i + 2]] += 1\n",
    "        else:\n",
    "            italian_currLetter[word[i : i + 2]] = 1\n",
    "    for i in range(len(word)):\n",
    "        if word[i] in italian_prevLetter.keys():\n",
    "            italian_prevLetter[word[i]] += 1\n",
    "        else:\n",
    "            italian_prevLetter[word[i]] = 1\n",
    "\n",
    "for key in italian_currLetter.keys():\n",
    "    italian_bigram[(key, key[0])] = italian_currLetter[key] / italian_prevLetter[key[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vocabulary for Test Data\n",
    "test_file = open('../Data/Validation/LangId.test', 'r', encoding = 'Latin1')\n",
    "lines = test_file.readlines()\n",
    "test_file.close()\n",
    "\n",
    "test_vocab = []\n",
    "for l in lines:\n",
    "    words = []\n",
    "    line_vocab = []\n",
    "    for p in string.punctuation:\n",
    "        l = l.replace(p, \"\")\n",
    "    words.append(l.strip().lower())\n",
    "\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        line_vocab.extend(words[i].split())\n",
    "        i += 1\n",
    "    test_vocab.append(line_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test English\n",
    "english_test_log = []\n",
    "\n",
    "for line_vocab in test_vocab:\n",
    "    test_log = 0\n",
    "    test_currLetter = {}\n",
    "    test_prevLetter = {}\n",
    "    for word in line_vocab:\n",
    "        for i in range(len(word) - 1):\n",
    "            if word[i : i + 2] not in test_currLetter.keys():\n",
    "                test_currLetter[word[i : i + 2]] = 0\n",
    "        for i in range(len(word) - 1):\n",
    "            if word[i] not in test_prevLetter.keys():\n",
    "                test_prevLetter[word[i]] = 0\n",
    "    \n",
    "    # Apply smoothing\n",
    "    # Sets up the bigram and pairs of words and adds the ones that havent been seen\n",
    "    for key in test_currLetter.keys():\n",
    "        if key[0] not in english_prevLetter:\n",
    "            english_prevLetter[key[0]] = 0\n",
    "        if key not in english_currLetter:\n",
    "            english_currLetter[key] = 0\n",
    "        if (key, key[0]) not in english_bigram.keys():\n",
    "            english_bigram[(key, key[0])] = 0\n",
    "\n",
    "    # Update bigram probabilities\n",
    "    for i in english_bigram:\n",
    "        english_bigram[i] = (english_currLetter[i[0]] + 1) / (english_prevLetter[i[1]] + len(english_prevLetter.keys()))\n",
    "\n",
    "\n",
    "    for letter in test_currLetter:\n",
    "        test_log += math.log(english_bigram[(letter, letter[0])], 2)\n",
    "\n",
    "    english_test_log.append(test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test French\n",
    "french_test_log = []\n",
    "\n",
    "for line_vocab in test_vocab:\n",
    "    test_log = 0\n",
    "    test_currLetter = {}\n",
    "    test_prevLetter = {}\n",
    "    for word in line_vocab:\n",
    "        for i in range(len(word) - 1):\n",
    "            if word[i : i + 2] not in test_currLetter.keys():\n",
    "                test_currLetter[word[i : i + 2]] = 0\n",
    "        for i in range(len(word) - 1):\n",
    "            if word[i] not in test_prevLetter.keys():\n",
    "                test_prevLetter[word[i]] = 0\n",
    "\n",
    "    # Apply smoothing\n",
    "    # Sets up the bigram and pairs of words and adds the ones that havent been seen\n",
    "    for key in test_currLetter.keys():\n",
    "        if key[0] not in french_prevLetter:\n",
    "            french_prevLetter[key[0]] = 0\n",
    "        if key not in french_currLetter:\n",
    "            french_currLetter[key] = 0\n",
    "        if (key, key[0]) not in french_bigram.keys():\n",
    "            french_bigram[(key, key[0])] = 0\n",
    "    \n",
    "    # Update bigram probabilities\n",
    "    for i in french_bigram:\n",
    "        french_bigram[i] = (french_currLetter[i[0]] + 1) / (french_prevLetter[i[1]] + len(french_prevLetter.keys()))\n",
    "\n",
    "\n",
    "    for letter in test_currLetter:\n",
    "        test_log += math.log(french_bigram[(letter, letter[0])], 2)\n",
    "\n",
    "    french_test_log.append(test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Italian\n",
    "italian_test_log = []\n",
    "\n",
    "for line_vocab in test_vocab:\n",
    "    test_log = 0\n",
    "    test_currLetter = {}\n",
    "    test_prevLetter = {}\n",
    "    for word in line_vocab:\n",
    "        for i in range(len(word) - 1):\n",
    "            if word[i : i + 2] not in test_currLetter.keys():\n",
    "                test_currLetter[word[i : i + 2]] = 0\n",
    "        for i in range(len(word) - 1):\n",
    "            if word[i] not in test_prevLetter.keys():\n",
    "                test_prevLetter[word[i]] = 0\n",
    "    \n",
    "    # Apply smoothing\n",
    "    # Sets up the bigram and pairs of words and adds the ones that havent been seen\n",
    "    for key in test_currLetter.keys():\n",
    "        if key[0] not in italian_prevLetter:\n",
    "            italian_prevLetter[key[0]] = 0\n",
    "        if key not in italian_currLetter:\n",
    "            italian_currLetter[key] = 0\n",
    "        if (key, key[0]) not in italian_bigram.keys():\n",
    "            italian_bigram[(key, key[0])] = 0\n",
    "\n",
    "    # Update bigram probabilities\n",
    "    for i in italian_bigram:\n",
    "        italian_bigram[i] = (italian_currLetter[i[0]] + 1) / (italian_prevLetter[i[1]] + len(italian_prevLetter.keys()))\n",
    "\n",
    "    \n",
    "    for letter in test_currLetter:\n",
    "        test_log += math.log(italian_bigram[(letter, letter[0])], 2)\n",
    "\n",
    "    italian_test_log.append(test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare and Write Predictions to Output File\n",
    "output_file = open('../Data/Output/letterLangId.out', 'w')\n",
    "\n",
    "for i in range(len(english_test_log)):\n",
    "    lang_prediction = max(english_test_log[i], french_test_log[i], italian_test_log[i])\n",
    "\n",
    "    if lang_prediction == english_test_log[i]:\n",
    "        output_file.write(str(i + 1) + \" English\")\n",
    "    elif lang_prediction == french_test_log[i]:\n",
    "        output_file.write(str(i + 1) + \" French\")\n",
    "    else:\n",
    "        output_file.write(str(i + 1) + \" Italian\")\n",
    "\n",
    "    if (i + 1 < len(english_test_log)):\n",
    "         output_file.write(\"\\n\")\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Prediction Accuracy\n",
    "prediction_file = open('../Data/Output/letterLangId.out', 'r')\n",
    "prediction_lines = prediction_file.readlines()\n",
    "prediction_file.close()\n",
    "\n",
    "solutions_file = open('../Data/Validation/labels.sol', 'r')\n",
    "solution_lines = solutions_file.readlines()\n",
    "solutions_file.close()\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(solution_lines)):\n",
    "    if prediction_lines[i] == solution_lines[i]:\n",
    "        correct += 1\n",
    "print(\"Prediction Accuracy: \" + str((correct/len(solution_lines)) * 100) + \"%\")"
   ]
  }
 ]
}