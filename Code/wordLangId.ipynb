{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "fa94fa03635b191b62c3bdd9f3230a84a78e4138ecf162410bfe25b45739a4b0"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read English Training Data\n",
    "# By: Benjamin Kulis\n",
    "import string, math\n",
    "\n",
    "input_file = open('../Data/Input/LangId.train.English', 'r', encoding = 'Latin1')\n",
    "lines = input_file.readlines()\n",
    "input_file.close()\n",
    "\n",
    "words = []\n",
    "english_vocab = []\n",
    "\n",
    "for l in lines:\n",
    "    for p in string.punctuation:\n",
    "        l = l.replace(p, \"\")\n",
    "    words.append(l.strip().lower())\n",
    "    \n",
    "i = 0\n",
    "while i < len(words):\n",
    "    english_vocab.extend(words[i].split())\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create English Bigram\n",
    "english_currWords = {}\n",
    "english_prevWord = {}\n",
    "english_bigram = {}\n",
    "\n",
    "for i in range(len(english_vocab) - 1):\n",
    "    if (english_vocab[i], english_vocab[i + 1]) in english_currWords.keys():\n",
    "        english_currWords[(english_vocab[i], english_vocab[i + 1])] += 1\n",
    "    else:\n",
    "        english_currWords[(english_vocab[i], english_vocab[i + 1])] = 1\n",
    "for i in range(len(english_vocab)):\n",
    "    if english_vocab[i] in english_prevWord.keys():\n",
    "        english_prevWord[english_vocab[i]] += 1\n",
    "    else:\n",
    "        english_prevWord[english_vocab[i]] = 1\n",
    "        \n",
    "for key in english_currWords.keys():\n",
    "    english_bigram[(key, key[0])] = english_currWords[key] / english_prevWord[key[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read French Training Data\n",
    "input_file = open('../Data/Input/LangId.train.French', 'r', encoding = 'Latin1')\n",
    "lines = input_file.readlines()\n",
    "input_file.close()\n",
    "\n",
    "words = []\n",
    "french_vocab = []\n",
    "\n",
    "for l in lines:\n",
    "    for p in string.punctuation:\n",
    "        l = l.replace(p, \"\")\n",
    "    words.append(l.strip().lower())\n",
    "    \n",
    "i = 0\n",
    "while i < len(words):\n",
    "    french_vocab.extend(words[i].split())\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create French Bigram\n",
    "french_currWords = {}\n",
    "french_prevWord = {}\n",
    "french_bigram = {}\n",
    "\n",
    "for i in range(len(french_vocab) - 1):\n",
    "    if (french_vocab[i], french_vocab[i + 1]) in french_currWords.keys():\n",
    "        french_currWords[(french_vocab[i], french_vocab[i + 1])] += 1\n",
    "    else:\n",
    "        french_currWords[(french_vocab[i], french_vocab[i + 1])] = 1\n",
    "for i in range(len(french_vocab)):\n",
    "    if french_vocab[i] in french_prevWord.keys():\n",
    "        french_prevWord[french_vocab[i]] += 1\n",
    "    else:\n",
    "        french_prevWord[french_vocab[i]] = 1\n",
    "        \n",
    "for key in french_currWords.keys():\n",
    "    french_bigram[(key, key[0])] = french_currWords[key] / french_prevWord[key[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read Italian Training Data\n",
    "input_file = open('../Data/Input/LangId.train.Italian', 'r', encoding = 'Latin1')\n",
    "lines = input_file.readlines()\n",
    "input_file.close()\n",
    "\n",
    "words = []\n",
    "italian_vocab = []\n",
    "\n",
    "for l in lines:\n",
    "    for p in string.punctuation:\n",
    "        l = l.replace(p, \"\")\n",
    "    words.append(l.strip().lower())\n",
    "    \n",
    "i = 0\n",
    "while i < len(words):\n",
    "    italian_vocab.extend(words[i].split())\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Italian Bigram\n",
    "italian_currWords = {}\n",
    "italian_prevWord = {}\n",
    "italian_bigram = {}\n",
    "\n",
    "for i in range(len(italian_vocab) - 1):\n",
    "    if (italian_vocab[i], italian_vocab[i + 1]) in italian_currWords.keys():\n",
    "        italian_currWords[(italian_vocab[i], italian_vocab[i + 1])] += 1\n",
    "    else:\n",
    "        italian_currWords[(italian_vocab[i], italian_vocab[i + 1])] = 1\n",
    "for i in range(len(italian_vocab)):\n",
    "    if italian_vocab[i] in italian_prevWord.keys():\n",
    "        italian_prevWord[italian_vocab[i]] += 1\n",
    "    else:\n",
    "        italian_prevWord[italian_vocab[i]] = 1\n",
    "        \n",
    "for key in italian_currWords.keys():\n",
    "    italian_bigram[(key, key[0])] = italian_currWords[key] / italian_prevWord[key[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vocabulary for Test Data\n",
    "test_file = open('../Data/Validation/LangId.test', 'r', encoding = 'Latin1')\n",
    "lines = test_file.readlines()\n",
    "test_file.close()\n",
    "\n",
    "test_vocab = []\n",
    "for l in lines:\n",
    "    words = []\n",
    "    line_vocab = []\n",
    "    for p in string.punctuation:\n",
    "        l = l.replace(p, \"\")\n",
    "    words.append(l.strip().lower())\n",
    "\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        line_vocab.extend(words[i].split())\n",
    "        i += 1\n",
    "    test_vocab.append(line_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test English\n",
    "english_test_log = []\n",
    "\n",
    "for line_vocab in test_vocab:\n",
    "    test_log = 0\n",
    "    test_currWords = []\n",
    "    test_prevWord = []\n",
    "    for i in range(len(line_vocab) - 1):\n",
    "        test_currWords.append((line_vocab[i], line_vocab[i + 1]))\n",
    "    for word in line_vocab:\n",
    "        test_prevWord.append(word)\n",
    "\n",
    "    # Apply smoothing\n",
    "    # Sets up the bigram and pairs of words and adds the ones that havent been seen\n",
    "    for word in test_currWords:\n",
    "        if word[0] not in english_prevWord.keys():\n",
    "            english_prevWord[word[0]] = 0\n",
    "        if word not in english_currWords.keys():\n",
    "            english_currWords[word] = 0\n",
    "        if (word, word[0]) not in english_bigram.keys():\n",
    "            english_bigram[(word, word[0])] = 0\n",
    "\n",
    "    # Update bigram probabilities\n",
    "    for i in english_bigram:\n",
    "        english_bigram[i] = (english_currWords[i[0]] + 1) / (english_prevWord[i[1]] + len(english_prevWord.keys())) # (c+1)/n+vocab size\n",
    "\n",
    "    for word in range(len(line_vocab) - 1):\n",
    "        test_log += math.log(english_bigram[((line_vocab[word], line_vocab[word + 1]), (line_vocab[word], line_vocab[word + 1])[0])], 2)\n",
    "    english_test_log.append(test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test French\n",
    "french_test_log = []\n",
    "\n",
    "for line_vocab in test_vocab:\n",
    "    test_log = 0\n",
    "    test_currWords = []\n",
    "    test_prevWord = []\n",
    "    for i in range(len(line_vocab) - 1):\n",
    "        test_currWords.append((line_vocab[i], line_vocab[i + 1]))\n",
    "    for word in line_vocab:\n",
    "        test_prevWord.append(word)\n",
    "\n",
    "    # Apply smoothing\n",
    "    # Sets up the bigram and pairs of words and adds the ones that havent been seen\n",
    "    for word in test_currWords:\n",
    "        if word[0] not in french_prevWord.keys():\n",
    "            french_prevWord[word[0]] = 0\n",
    "        if word not in french_currWords.keys():\n",
    "            french_currWords[word] = 0\n",
    "        if (word, word[0]) not in french_bigram.keys():\n",
    "            french_bigram[(word, word[0])] = 0\n",
    "\n",
    "    # Update bigram probabilities\n",
    "    for i in french_bigram:\n",
    "        french_bigram[i] = (french_currWords[i[0]] + 1) / (french_prevWord[i[1]] + len(french_prevWord.keys()))\n",
    "\n",
    "    for word in range(len(line_vocab) - 1):\n",
    "        test_log += math.log(french_bigram[((line_vocab[word], line_vocab[word + 1]), (line_vocab[word], line_vocab[word + 1])[0])], 2)\n",
    "    french_test_log.append(test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Italian\n",
    "italian_test_log = []\n",
    "\n",
    "for line_vocab in test_vocab:\n",
    "    test_log = 0\n",
    "    test_currWords = []\n",
    "    test_prevWord = []\n",
    "    for i in range(len(line_vocab) - 1):\n",
    "        test_currWords.append((line_vocab[i], line_vocab[i + 1]))\n",
    "    for word in line_vocab:\n",
    "        test_prevWord.append(word)\n",
    "\n",
    "    # Apply smoothing\n",
    "    # Sets up the bigram and pairs of words and adds the ones that havent been seen\n",
    "    for word in test_currWords:\n",
    "        if word[0] not in italian_prevWord.keys():\n",
    "            italian_prevWord[word[0]] = 0\n",
    "        if word not in italian_currWords.keys():\n",
    "            italian_currWords[word] = 0\n",
    "        if (word, word[0]) not in italian_bigram.keys():\n",
    "            italian_bigram[(word, word[0])] = 0\n",
    "            \n",
    "    # Update bigram probabilities\n",
    "    for i in italian_bigram:\n",
    "        italian_bigram[i] = (italian_currWords[i[0]] + 1) / (italian_prevWord[i[1]] + len(italian_prevWord.keys()))\n",
    "\n",
    "    for word in range(len(line_vocab) - 1):\n",
    "        test_log += math.log(italian_bigram[((line_vocab[word], line_vocab[word + 1]), (line_vocab[word], line_vocab[word + 1])[0])], 2)\n",
    "    italian_test_log.append(test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare and Write Predictions to Output File\n",
    "output_file = open('../Data/Output/wordLangId.out', 'w')\n",
    "\n",
    "for i in range(len(english_test_log)):\n",
    "    lang_prediction = max(english_test_log[i], french_test_log[i], italian_test_log[i])\n",
    "\n",
    "    if lang_prediction == english_test_log[i]:\n",
    "        output_file.write(str(i + 1) + \" English\")\n",
    "    elif lang_prediction == french_test_log[i]:\n",
    "        output_file.write(str(i + 1) + \" French\")\n",
    "    else:\n",
    "        output_file.write(str(i + 1) + \" Italian\")\n",
    "\n",
    "    if (i + 1 < len(english_test_log)):\n",
    "         output_file.write(\"\\n\")\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction Accuracy: 99.0%\n"
     ]
    }
   ],
   "source": [
    "# Check Prediction Accuracy\n",
    "prediction_file = open('../Data/Output/wordLangId.out', 'r')\n",
    "prediction_lines = prediction_file.readlines()\n",
    "prediction_file.close()\n",
    "\n",
    "solutions_file = open('../Data/Validation/labels.sol', 'r')\n",
    "solution_lines = solutions_file.readlines()\n",
    "solutions_file.close()\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(solution_lines)):\n",
    "    if prediction_lines[i] == solution_lines[i]:\n",
    "        correct += 1\n",
    "print(\"Prediction Accuracy: \" + str((correct/len(solution_lines)) * 100) + \"%\")"
   ]
  }
 ]
}